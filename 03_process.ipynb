{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using `yadg` to process multiple files into one data archive\n",
    "If one wishes to process multiple files, whether of the same or different filetypes, into a single data archive, `yadg` offers a convenient way of doing so by using the `yadg process` command coupled with a *DataSchema*. The usage of the `yadg process` command can be accessed using the `--help` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yadg process --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the `infile` argument is a *DataSchema* file (JSON or YAML) specifying which files and folders are to be processed, and how. The *DataSchema* is documented in the [`dgbowl_schemas` package](https://dgbowl.github.io/dgbowl-schemas/master/apidoc/dgbowl_schemas.yadg.dataschema.html#module-dgbowl_schemas.yadg.dataschema); we will highlight the main functionalities below.\n",
    "\n",
    "The `outfile` argument specifies the path of the output NetCDF file. Unlike in the [`yadg extract` usage](02_extract.ipynb), here the NetCDF file contains a `Datatree` as opposed to a `xarray.Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Main features of a *DataSchema*\n",
    "The default *DataSchema* for `yadg-5.0` is *DataSchema-5.0*, which is composed of three elements:\n",
    "\n",
    "  - `metadata`, containing versioning and provenance information \n",
    "  - `step_defaults`, providing defaults for timezones, locales and file encoding,\n",
    "  - `steps`, enumerating instructions for parsing of sets of files.\n",
    "\n",
    "Note that previous versions of *DataSchemas* can be still used with `yadg-5.0`, as they will be automatically updated to the latest version, using default settings as necessary.\n",
    "\n",
    "### 3.1.1 *DataSchema->`metadata`*\n",
    "\n",
    "    metadata:\n",
    "        provenance:\n",
    "            type: manual\n",
    "        version: \"5.0\"\n",
    "\n",
    "The above example shows a sample `metadata` section of a valid *DataSchema-5.0*. The entries are:\n",
    "\n",
    "  - `metadata->provenance->type` entry: a required string annotation of the *DataSchema* provenance, with `\"manual\"` denoting a hand-written schema (alternatives include `yadg extract`, if an internal *DataSchema* has been generated in the course of `yadg extract` run, etc.)\n",
    "  - `metadata->version` entry: is a required string literal (not a float!) equal to `\"5.0\"`\n",
    "\n",
    "### 3.1.2 *DataSchema->`step_defaults`*\n",
    "\n",
    "    step_defaults:\n",
    "        timezone: Europe/Berlin\n",
    "\n",
    "The above example shows a sample `step_defaults` section of a valid *DataSchema-5.0*. The whole section is optional, however specifying at least the `step_defaults->timezone` is good practice, as the `timezone` is used to make all `DateTime` objects within `yadg` timezone-aware. The specified `timezone` should be that of the data, not of the computer where the data is being processed. A wrong `timezone` might lead to wrong unix timestamps, but more crucially, to relative off-by-hour errors (e.g. when measurements span daylight savings adjustment) or even worse errors when combining data containing timezone-aware timestamps with other, unannotated data.\n",
    "\n",
    "Other optional entries are the `locale`, which switches on locale-aware processing of certain text file types (decimal and thousand separators), and `encoding`, which adjusts the default encoding (`UTF-8`) for all files.\n",
    "\n",
    "### 3.1.3 *DataSchema->`steps`*\n",
    "    \n",
    "    steps:\n",
    "      - parser: electrochem\n",
    "        input:\n",
    "            folders: [\"process/data\"]\n",
    "            suffix: \"mpr\"\n",
    "        extractor:\n",
    "          filetype: \"eclab.mpr\"\n",
    "        tag: electro\n",
    "\n",
    "The above example shows one *step*, i.e. a block in the `steps` enumeration. The following entries are required:\n",
    "\n",
    "  - `parser`, denoting the `yadg` parser used to process the matched files\n",
    "  - `input`, specifying files to be processed directly, or matched within the specified folders using filename components,\n",
    "  - `extractor->filetype`, specifying the filetype of the matched files.\n",
    "\n",
    "Note that some `filetypes` may be processed by more than one `parser`, which is why both have to be specified. All files matched by the `input` section will be collated into one node in the resulting `Datatree`.\n",
    "\n",
    "## 3.2 Usage example: electrochemistry and gas chromatography\n",
    "A sample *DataSchema* is located in the [`process/ds.5.0.yml`](process/ds.5.0.yml) file. It contains the same `metadata` and `step_defaults` sections as above, but it has two steps:\n",
    "\n",
    "- the first processing any files present in the `process/data/` folder, which have a `mpr` suffix and contain `LSV` in their filename, treating them as an `eclab.mpr` filetype,\n",
    "- the second processing a single specified `process/data/CuDura05_03.zip` archive, treating it as a `fusion.zip` filetype.\n",
    "\n",
    "We can process this *DataSchema*, generating a NetCDF file in `process/output.nc`, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yadg process process/ds.5.0.yml process/output.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `yadg process` stores `DataTree` objects in the NetCDF file instead of a simple `xarray.Dataset`. We can have a look at what is in the file using the `xarray-datatree` package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatree import open_datatree\n",
    "dt = open_datatree(\"process/output.nc\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the individual leaves of the `DataTree` containing our data using dictionary notation. For this we can use the `tag` entries in the respective steps (i.e. `LSV` and `GC`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(dt[\"LSV\"])\n",
    "display(dt[\"GC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the first leaf, `LSV`, corresponds to the first *step* and contains 235 points along the `uts` dimension; the second leaf, `GC`, corresponds to the second *step*, and contains 120 points along the `uts` dimension with an additional `species` dimension.\n",
    "\n",
    "As the `uts` timestamps are referencing the Unix epoch, the data is guaranteed to be properly aligned in time, assuming the `timezone` of the data files has been set properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to index](index.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yadg-examples",
   "language": "python",
   "name": "yadg-examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
